{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "760fdd76-0d5f-42f6-82a2-4b1a34171209",
   "metadata": {},
   "source": [
    "## Recommender System\n",
    "\n",
    "#### Davy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "671b395d-76ee-48f8-8086-5fb91a243212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload local python files every 2 seconds\n",
    "            \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba8028b2-f4b5-4a81-bd55-4fbb67743808",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Bias import *\n",
    "from LatentFactor import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e582403-6268-40a1-9b58-6dc8e427b299",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Read data from \"*.JSON\" file. \n",
    "##Each line is a dictionary. \n",
    "path1 = \"goodreads_reviews_historybio_train.json\"\n",
    "path2 = \"goodreads_reviews_historybio_test.json\"\n",
    "path3 = \"goodreads_reviews_historybio_val.json\"\n",
    "\n",
    "try:\n",
    "    with open(path1,'r') as training_file:\n",
    "        training = []\n",
    "        for line in training_file:\n",
    "            json_data1 = json.loads(line)\n",
    "            training.append(json_data1)\n",
    "        training_file.close()\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"file open failed.\")\n",
    "\n",
    "try:\n",
    "    with open(path2,'r') as test_file:\n",
    "        test = []\n",
    "        for line in test_file:\n",
    "            json_data2 = json.loads(line)\n",
    "            test.append(json_data2)\n",
    "        test_file.close()\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"file open failed.\")\n",
    "\n",
    "try:\n",
    "    with open(path3,'r') as validation_file:\n",
    "        val = []\n",
    "        for line in validation_file:\n",
    "            json_data3 = json.loads(line)\n",
    "            val.append(json_data3)\n",
    "        validation_file.close()\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"file open failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9ece83-77ee-49e6-a5ab-4b71d95fc544",
   "metadata": {},
   "source": [
    "### Section 1: Explore biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6a16fc-efe3-4607-b6b7-902238387c2f",
   "metadata": {},
   "source": [
    "##### Calculate the global bias $b_g$, user specific bias $b_i^{(user)}$ and item specific bias $b_j^{(item)}$ on the **training data**. Report:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063b6a7d-d126-47ed-9379-a56a04cd1e21",
   "metadata": {},
   "source": [
    "##### (A)The global $b_g$ bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd8c69af-cefe-4e17-8a60-f82df979bcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The global bias is :3.7670\n"
     ]
    }
   ],
   "source": [
    "bg = Global_Bias(training)\n",
    "\n",
    "print(f'The global bias is :{bg:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c963d013-941c-49a3-924c-d57147208a65",
   "metadata": {},
   "source": [
    "##### (B)The user specific bias of user id= “3913f3be1e8fadc1de34dc49dab06381”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28d58ecc-80bb-46d2-9a24-8c8ad183cbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "usr_train = Dictionary(training, 'user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9a16653-1cdf-405a-b2cc-f7cb76583297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user specific bias of user_id= “3913f3be1e8fadc1de34dc49dab06381” is :-0.1139\n"
     ]
    }
   ],
   "source": [
    "spcific_uid = usr_train['3913f3be1e8fadc1de34dc49dab06381'] #Convert the \"user id \" to index.\n",
    "\n",
    "bi  = User_Bias(training, usr_train) #Calculate the user bias for the whole dataset.\n",
    "single_usr_bias = bi[spcific_uid] #Specific \"user_id\" bias\n",
    "\n",
    "print(f'The user specific bias of user_id= “3913f3be1e8fadc1de34dc49dab06381” is :{single_usr_bias:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf20229f-00cc-4055-8e99-dfffbeb7a767",
   "metadata": {},
   "source": [
    "##### (C) The item specific bias of book id = “16130”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f08f6a4-8f1c-44b1-9d02-e60f7aae885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "it_train = Dictionary(training, 'book_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d528c67-af42-4103-9aa8-3cd7753fc7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The item specific bias of book_id = “16130” is :0.4563\n"
     ]
    }
   ],
   "source": [
    "specific_bid = it_train['16130'] #Convert the \"book id \" to index.\n",
    "\n",
    "bj= Item_Bias(training, it_train) #Calculate the item bias for the whole dataset.\n",
    "single_book_bias = bj[specific_bid]#Specific \"book_id\" bias\n",
    "\n",
    "print(f'The item specific bias of book_id = “16130” is :{single_book_bias:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bf82fa-2e52-4760-b216-11dc7283e0e0",
   "metadata": {},
   "source": [
    "### Section 2: Implement the regularized latent factor model without bias using SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7079714b-f5c9-4171-8fb8-ccb1bdaeca94",
   "metadata": {},
   "source": [
    "##### (A) Implement the regularized latent factor model without considering the bias. The optimization problem that needs to be solved is (see slide 8 of W9.2 lecture notes):\n",
    "<center>$\\ ^{\\mathrm{min}}_{\\mathrm{P,Q}} \\sum_{r_{ij}\\in R}(r_{ij} − \\textbf{q}^T_i · \\textbf{p}_j )^2 + \\lambda _1 \\sum_{i \\in U}||\\textbf{q}_i||^2_2 + \\lambda _2 \\sum_{j \\in P}|| \\textbf{p}_j ||^2_2$</center>\n",
    "<br>\n",
    "\n",
    "The initialization of **P** and **Q** should be random, from a normal distribution. Set the number of latent factors to $k$ = 8. Use Stochastic Gradient Descent (SGD) to solve the optimization problem on the **training data** (see slide 9 of W9.2 lecture notes). Run SGD for 10 iterations (also called epoches), with a fixed learning rate $\\eta$ = 0.01 and regularization hyperparameters $\\lambda _1 = \\lambda _2 $= 0.3. Remember that the regularization terms involve the L2-norms of the $q_i$ and $p_j$ vectors for each user $i$ and item $j$ respectively.\n",
    "\n",
    "Report the RMSE on the training data for each epoch, by using the RMSE formula (see slide 36 of W8 lecture notes):\n",
    "\n",
    "<center>$RMSE=\\sqrt {\\frac{1}{|R|} \\sum_{{i,j}\\in {R}}(r_{ij}-\\hat{r_{ij}})^2}$</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fc726e8-4ae6-4d0b-a6b3-43c4ccbda55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#P, Q, R initialisation \n",
    "\n",
    "Factor = 8\n",
    "\n",
    "q_train = Latent_factor(len(usr_train), Factor) \n",
    "p_train = Latent_factor(len(it_train), Factor)\n",
    "r_train = Interaction_dataframe(training, usr_train, it_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9739052b-a46f-4e27-b643-20ff3e69d19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall, the rating system looks like: \n",
      "         user_id  book_id  rating\n",
      "0          22460     3223       5\n",
      "1         160446    59273       5\n",
      "2         181493    66973       3\n",
      "3          84669   161052       2\n",
      "4           8478    55311       3\n",
      "...          ...      ...     ...\n",
      "1239710   194226   175926       5\n",
      "1239711   174601   185828       3\n",
      "1239712     6216    10967       5\n",
      "1239713    55949   116015       5\n",
      "1239714   194242   106531       5\n",
      "\n",
      "[1239715 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(f'Overall, the rating system looks like: \\n{r_train}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3deb7b46-4f03-41fa-aa4c-dccb7c5781f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_train = SGD_LFM(r_train, q_train, p_train, Factor, 10, 0.3, 0.3, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "598f7fbc-b2fc-4e76-8f64-27a2f3940345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the RMSE on the training data for each epoch are : {1: 4.363282, 2: 3.661844, 3: 3.069793, 4: 2.557558, 5: 2.175528, 6: 1.888099, 7: 1.669095, 8: 1.500498, 9: 1.369611, 10: 1.26722}\n"
     ]
    }
   ],
   "source": [
    "print(f'the RMSE on the training data for each epoch are : {RMSE_train}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457b230c-5399-43ca-b4a7-19104b75749f",
   "metadata": {},
   "source": [
    "##### (B) Use SGD to train the latent factor model on the **training data** for different values of $k$ in {4,8,16}. For each value of $k$, train the model for 10 epoches/iterations. Report the **RMSE** for each value of k on the **validation data**. Pick the model that results in the best **RMSE** on the **validation set** and report its **RMSE** on the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cf8fabd-bc4e-4e78-a4e9-b23ecf3b31e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Factor_list= [4, 8, 16]\n",
    "RMSE = {}\n",
    "\n",
    "for k in Factor_list:\n",
    "\n",
    "    total = [x for x in training] + [x for x in val] + [x for x in test] #The total list combines training, val and test set\n",
    "    usr_total = Dictionary(total, 'user_id') \n",
    "    it_total = Dictionary(total, 'book_id')\n",
    "\n",
    "    #Training the latent factors P and Q on the total list\n",
    "    q_total = Latent_factor(len(usr_total), k)\n",
    "    p_total= Latent_factor(len(it_total), k) \n",
    "\n",
    "    r_val = Interaction_dataframe( val, usr_total, it_total ) \n",
    "\n",
    "    RMSE[ k ]  = SGD_LFM(r_val, q_total, p_total, k, 10, 0.3, 0.3, 0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bcf9542-0c73-40a3-a8dc-d8bbde22c96a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When the k is 4,the RMSE is:\n",
      "\n",
      "{1: 4.254102, 2: 3.833583, 3: 3.619951, 4: 3.417427, 5: 3.183338, 6: 2.925594, 7: 2.669875, 8: 2.4321, 9: 2.218197, 10: 2.028968}\n",
      "\n",
      "When the k is 8,the RMSE is:\n",
      "\n",
      "{1: 4.524966, 2: 3.6585, 3: 3.303403, 4: 3.027226, 5: 2.762207, 6: 2.493667, 7: 2.232126, 8: 1.992416, 9: 1.782243, 10: 1.602799}\n",
      "\n",
      "When the k is 16,the RMSE is:\n",
      "\n",
      "{1: 5.041389, 2: 3.240417, 3: 2.757906, 4: 2.419278, 5: 2.120636, 6: 1.851766, 7: 1.619825, 8: 1.427947, 9: 1.273263, 10: 1.150074}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Report the RMSE for the val set\n",
    "\n",
    "for key, value in RMSE.items():\n",
    "   \n",
    "    print(f'When the k is {key},the RMSE is:\\n')\n",
    "    print(f'{RMSE[ key ]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d823b86-d7ab-4684-b3fc-e6358664931a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best k value is 16\n"
     ]
    }
   ],
   "source": [
    "#Select the minimal RMSE and return k\n",
    "\n",
    "min_error = np.inf\n",
    "\n",
    "for key, values in RMSE.items():\n",
    "  \n",
    "    l_key =list(RMSE[ key ].keys())[ -1 ]\n",
    "    \n",
    "    if RMSE[ key ][ l_key ] < min_error:\n",
    "        best_k = key\n",
    "        min_error =  RMSE[ key ][ l_key ] \n",
    "\n",
    "print(f'The best k value is {best_k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70ea1a39-de39-4985-a130-85cbbe40f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_test = Interaction_dataframe(test, usr_total, it_total ) \n",
    "\n",
    "#Use the \"best_k\" from Val set to test the test set\n",
    "RMSE_test= SGD_LFM(r_test, q_total, p_total, best_k ,10, 0.3, 0.3, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cc45800-2587-4c50-9096-b72e8de0e30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the RMSE on the test data for each epoch are : {1: 4.26514, 2: 2.810147, 3: 2.195511, 4: 1.795294, 5: 1.508608, 6: 1.29784, 7: 1.141721, 8: 1.025349, 9: 0.937787, 10: 0.871092}\n"
     ]
    }
   ],
   "source": [
    "print(f'the RMSE on the test data for each epoch are : {RMSE_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3962ae00-47a3-4701-8381-e2d8ae72ba95",
   "metadata": {},
   "source": [
    "\n",
    "### Section 3: Implement the regularized latent factor model with bias using SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1745b004-e6ec-43e0-bc4f-d8cd60c73da7",
   "metadata": {},
   "source": [
    "##### (A) Incorporate the bias terms $b_g$, $b_i^{(user)}$ and $b_j^{(item)}$ to the latent factor model. The optimization problem that needs to be solved is (see slide 11 of W9.2 lecture notes):\n",
    "\n",
    "<center>$\\ ^{\\  \\mathrm{    min }}_{\\mathrm{P,Q,b_i,b_j}} \\sum_{r_{ij}\\in R}(r_{ij} −\\textbf{q}^T_i · \\textbf{p}_j -b_{ij})^2 + \\lambda _1 \\sum_{i \\in U}||\\textbf{q}_i||^2_2 + \\lambda _2 \\sum_{j \\in P}|| \\textbf{p}_j ||^2_2 + \\lambda _3 \\sum_{i \\in U}( b_i^{(user)} )^2_2 +\\lambda _4 \\sum_{j \\in P}( b_j^{(item)} )^2_2$</center>\n",
    "<br/>\n",
    "\n",
    "The initialization of **P** and **Q** should be random, from a normal distribution. Initialize the user bias $b_i^{(user)}$ and item bias terms $b_j^{(item)}$ using the values computed in Task 1. Set the number of latent factors $k$ = 8. Run SGD for 10 epoches with a fixed learning rate $\\eta$ = 0.01 and regularization hyperparameters $\\lambda$1 = $\\lambda$2 = $\\lambda$3 = $\\lambda$4 = 0.3. Report the RMSE on the training data for each epoch. After finishing all epoches, report the learned user-specific bias of the user with user_id= “3913f3be1e8fadc1de34dc49dab06381” , and the learned item- specific bias of the book with book_id = “16130”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46870aae-872f-4aeb-918e-ef9da1974c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_2, Bi_trained, Bj_trained, P_trained, Q_trained = SGD_LFM_bias(r_train, q_train, p_train, bg, bi, bj, Factor, 10, 0.3, 0.3, 0.3, 0.3, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e724f541-f69d-4520-b83f-4c80c845f8b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the RMSE on the training data with bias terms for each epoch are : {1: 1.865964, 2: 1.111793, 3: 0.944602, 4: 0.876734, 5: 0.844411, 6: 0.827238, 7: 0.817255, 8: 0.810979, 9: 0.806748, 10: 0.803716}\n"
     ]
    }
   ],
   "source": [
    "print(f'the RMSE on the training data with bias terms for each epoch are : { RMSE_2 }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bd72a7a-3d25-4398-87f2-300189a877b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user specific bias of user_id= “3913f3be1e8fadc1de34dc49dab06381 ” after finishing all epoches is :0.0013\n"
     ]
    }
   ],
   "source": [
    "single_usr_bias2 = Bi_trained[spcific_uid]\n",
    "b_uid_trained = single_usr_bias2 \n",
    "\n",
    "print(f'The user specific bias of user_id= “3913f3be1e8fadc1de34dc49dab06381 ” after finishing all epoches is :{b_uid_trained:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0170693e-1b80-4c5b-9f0b-f61997bad530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The item specific bias of book_id = “16130”  after finishing all epoches is :0.3587\n"
     ]
    }
   ],
   "source": [
    "single_book_bias2 = Bj_trained[specific_bid]\n",
    "b_itid_trained = single_book_bias2 \n",
    "\n",
    "print(f'The item specific bias of book_id = “16130”  after finishing all epoches is :{b_itid_trained:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35908f25-122d-4908-9541-e9c8259fd7e4",
   "metadata": {},
   "source": [
    "##### (B) Similar to Task 2 (B), find the best $k$ in {4, 8, 16} for the model you developed in Task 3 (A) on the validation set, by using **RMSE** to compare across these models, and apply the best of these models to the test data. Compare the resulting test **RMSE** with Task 2 (B). Analyse and explain your findings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4adf07c9-af70-4a0a-a010-d20c04d77233",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_2 = {}\n",
    "\n",
    "#Initialise the bias terms bg, bi and bj.\n",
    "#P and Q was initialised in 2(B)\n",
    "bi_val  = User_Bias(val, usr_total)\n",
    "bj_val = Item_Bias(val, it_total)\n",
    "bg_val = Global_Bias( val )\n",
    " \n",
    "for k in Factor_list:\n",
    "\n",
    "    RMSE_2[ k ] = SGD_LFM_bias(r_val, q_total, p_total, bg_val, bi_val, bj_val, k, 10, 0.3, 0.3, 0.3, 0.3, 0.01)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f82fbcf-a36d-4013-a12f-667dfa4fee95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When the k is 4,the RMSE is:\n",
      "\n",
      "{1: 2.606012, 2: 2.054839, 3: 1.806251, 4: 1.645682, 5: 1.530271, 6: 1.442324, 7: 1.372627, 8: 1.315729, 9: 1.26815, 10: 1.227553}\n",
      "\n",
      "When the k is 8,the RMSE is:\n",
      "\n",
      "{1: 1.136526, 2: 1.039368, 3: 0.992343, 4: 0.960732, 5: 0.936682, 6: 0.917033, 7: 0.900244, 8: 0.885468, 9: 0.872203, 10: 0.86013}\n",
      "\n",
      "When the k is 16,the RMSE is:\n",
      "\n",
      "{1: 0.724968, 2: 0.632431, 3: 0.610508, 4: 0.601093, 5: 0.595955, 6: 0.59266, 7: 0.59029, 8: 0.588447, 9: 0.586936, 10: 0.585652}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Report the RMSE for the val set\n",
    "\n",
    "for key, value in RMSE_2.items():\n",
    "   \n",
    "    print(f'When the k is {key},the RMSE is:\\n')\n",
    "    print(f'{RMSE_2[ key ]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a0f0a27-486f-4519-b4ae-86c9f3e909ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best k value is 16\n"
     ]
    }
   ],
   "source": [
    "#Select the minimal RMSE and return k\n",
    "\n",
    "min_error = np.inf\n",
    "\n",
    "for key, values in RMSE_2.items():\n",
    "  \n",
    "    l_key =list(RMSE_2[ key ].keys())[ -1 ]\n",
    "    \n",
    "    if RMSE_2[ key ][ l_key ] < min_error:\n",
    "        best_k_2 = key\n",
    "        min_error =  RMSE_2[ key ][ l_key ] \n",
    "\n",
    "print(f'The best k value is {best_k_2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54ef8eaf-5293-4bda-a468-35a507c159f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the bias terms bg, bi and bj for test set.\n",
    "bi_test  = User_Bias(test, usr_total)\n",
    "bj_test = Item_Bias(test, it_total)\n",
    "bg_test = Global_Bias( test )\n",
    "\n",
    "#Use the \"best_k_2\" from Val set to test the test set\n",
    "RMSE_test2 = SGD_LFM_bias(r_test, q_total, p_total, bg_test, bi_test, bj_test, best_k_2, 10, 0.3, 0.3, 0.3, 0.3, 0.01)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b406cdd2-8655-481a-b8dd-6c3f2066ab80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the RMSE on the test data with bias terms for each epoch are : {1: 1.66526, 2: 1.021557, 3: 0.803163, 4: 0.715255, 5: 0.675585, 6: 0.655299, 7: 0.643523, 8: 0.635851, 9: 0.630354, 10: 0.626117}\n"
     ]
    }
   ],
   "source": [
    "print(f'the RMSE on the test data with bias terms for each epoch are : {RMSE_test2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04010d8a-45f1-401f-b168-39479953c72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare the resulting test RMSE with Task 2.\n",
      "\n",
      "\t\tNo bias term\tWith bias term \n",
      "\n",
      "Epoch 1: \t 4.26514 \t1.66526\n",
      "Epoch 2: \t 2.810147 \t1.021557\n",
      "Epoch 3: \t 2.195511 \t0.803163\n",
      "Epoch 4: \t 1.795294 \t0.715255\n",
      "Epoch 5: \t 1.508608 \t0.675585\n",
      "Epoch 6: \t 1.29784 \t0.655299\n",
      "Epoch 7: \t 1.141721 \t0.643523\n",
      "Epoch 8: \t 1.025349 \t0.635851\n",
      "Epoch 9: \t 0.937787 \t0.630354\n",
      "Epoch 10: \t 0.871092 \t0.626117\n"
     ]
    }
   ],
   "source": [
    "print('Compare the resulting test RMSE with Task 2.\\n')\n",
    "\n",
    "print('\\t\\tNo bias term\\tWith bias term \\n')\n",
    "\n",
    "for key in range(10):\n",
    "    value1 = RMSE_test[key + 1]\n",
    "    value2 = RMSE_test2[key + 1]\n",
    "    print(f'Epoch {key + 1}: \\t {value1} \\t{value2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e2d03c-3d44-4181-8f60-48a4960d8e42",
   "metadata": {},
   "source": [
    "##### **Comments**: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a5d9a6-1f6f-4056-9a1e-cbc2db11e7d6",
   "metadata": {},
   "source": [
    "The RMSE result in 3B is significant better than 2B "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daaefd3-3e83-40e8-9221-366e8233a096",
   "metadata": {},
   "source": [
    "##### **Introducing bias terms** into latent factor models can improve the performance of the model. \n",
    "\n",
    "This is because bias terms can better capture personalised features and preferences between users and items, thereby enhancing the model's predictive accuracy. Each user and item can have different bias terms, reflecting their personalized interactions. This is crucial for predicting a user's interest in a specific item or other user-item interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad6667d0-98e5-402d-bb71-b49fc8179038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "0         0.014409\n",
       "1        -0.565659\n",
       "2        -0.370377\n",
       "3         0.328671\n",
       "4        -0.111219\n",
       "            ...   \n",
       "196661   -0.128537\n",
       "196662    1.086705\n",
       "196663    0.255969\n",
       "196664    0.030883\n",
       "196665   -0.075127\n",
       "Length: 196666, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " Bi_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9939371-1dbb-4512-8536-c807406874f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "book_id\n",
       "0         0.004367\n",
       "1         0.145095\n",
       "2         0.930291\n",
       "3        -0.353638\n",
       "4         0.526738\n",
       "            ...   \n",
       "232098    0.084968\n",
       "232099   -1.683639\n",
       "232100    1.030946\n",
       "232101    0.536694\n",
       "232102    0.076925\n",
       "Length: 232103, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " Bj_trained"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
